{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cd .."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b26046a",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import pandas as pd\n",
    "from src.loaders.load_data import load_data\n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54e941e",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "X = np.random.choice([0, 1], size=(100, 1))\n",
    "est = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform', subsample = None)\n",
    "est.fit_transform(X)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "29962f1a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9a9f4a",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def show_heatmap(df, figsize=(8, 6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(df.corr(), annot=True, fmt=\".2f\")\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c065f7f0",
   "metadata": {},
   "source": [
    "def avg_correlation(df):\n",
    "    avg_correlation_cols = list(OrderedDict(df.corr().abs().mean().sort_values(ascending=False).to_dict()).items())\n",
    "    features = set(df.columns.tolist()[:-1])\n",
    "    avg_correlation_cols = [col for col in avg_correlation_cols if col[0] in features]\n",
    "    return avg_correlation_cols"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9707b1d5",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def kbins(data, data_config):\n",
    "\n",
    "    est = KMeans(n_clusters=10, random_state=0)\n",
    "\n",
    "    X = data.iloc[:, data_config['split_col_idx']].values\n",
    "    X = est.fit_predict(X)\n",
    "    \n",
    "    return X"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "494b7397",
   "metadata": {},
   "source": [
    "## Codrna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f594643",
   "metadata": {},
   "source": [
    "df, data_config = load_data('codrna')\n",
    "show_heatmap(df,  figsize = (6,4))\n",
    "print(avg_correlation(df))\n",
    "print(data_config)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abd0da75",
   "metadata": {},
   "source": [
    "avg_cols = avg_correlation(df)\n",
    "avg_cols = [col[0] for col in avg_cols]\n",
    "split_col_idx = [df.columns.tolist().index(col) for col in avg_cols]\n",
    "split_col_idx"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c881b23c",
   "metadata": {},
   "source": [
    "cl = kbins(df, data_config)\n",
    "np.unique(cl, return_counts=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0752c46",
   "metadata": {},
   "source": [
    "data_config"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c9b14ce9",
   "metadata": {},
   "source": [
    "## HHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14b452c6",
   "metadata": {},
   "source": [
    "\n",
    "############################################################################################################\n",
    "# Load data\n",
    "# members\n",
    "df_members = pd.read_csv('./data/HHP_herritage_health/Members.csv')\n",
    "df_members['Sex'] = df_members['Sex'].map({'M': 1, 'F': 0})\n",
    "df_members['AgeAtFirstClaim'] = df_members['AgeAtFirstClaim'].map({\n",
    "    '0-9': 5,\n",
    "    '10-19': 15,\n",
    "    '20-29': 25,\n",
    "    '30-39': 35,\n",
    "    '40-49': 45,\n",
    "    '50-59': 55,\n",
    "    '60-69': 65,\n",
    "    '70-79': 75,\n",
    "    '80+': 90\n",
    "})\n",
    "\n",
    "# drug and lab\n",
    "df_drug = pd.read_csv('./data/HHP_herritage_health/DrugCount.csv')\n",
    "df_drug['DrugCount'] = df_drug['DrugCount'].map({'1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7+': 10})\n",
    "df_lab = pd.read_csv('./data/HHP_herritage_health/LabCount.csv')\n",
    "df_lab['LabCount'] = df_lab['LabCount'].map(\n",
    "    {'1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10+': 12}\n",
    ")\n",
    "\n",
    "# days\n",
    "df_days_y2 = pd.read_csv('./data/HHP_herritage_health/DaysInHospital_Y2.csv')\n",
    "df_days_y2['Year'] = 'Y1'\n",
    "df_days_y3 = pd.read_csv('./data/HHP_herritage_health/DaysInHospital_Y3.csv')\n",
    "df_days_y3['Year'] = 'Y2'\n",
    "\n",
    "df_days = pd.concat([df_days_y2, df_days_y3])\n",
    "\n",
    "df_claims = pd.read_csv('./data/HHP_herritage_health/Claims.csv')\n",
    "\n",
    "# divide by provider\n",
    "# providers = df_claims['ProviderID'].value_counts().iloc[: 10].index.tolist()\n",
    "# df_claims = df_claims[df_claims['ProviderID'].isin(providers)]\n",
    "# print(df_claims.shape)\n",
    "\n",
    "df_claims = pd.merge(df_claims, df_members, on='MemberID', how='left')\n",
    "df_claims = pd.merge(df_claims, df_drug, on=['MemberID', 'Year', 'DSFS'], how='left')\n",
    "df_claims = pd.merge(df_claims, df_lab, on=['MemberID', 'Year', 'DSFS'], how='left')\n",
    "df_claims = pd.merge(df_claims, df_days, on=['MemberID', 'Year'], how='left')\n",
    "df_claims = df_claims[df_claims['DaysInHospital'].notna()]\n",
    "print(df_claims.shape)\n",
    "\n",
    "#################################################################################################################\n",
    "# Feature engineering\n",
    "# drop missing age and sex\n",
    "df_claims = df_claims[df_claims['AgeAtFirstClaim'].notna()].copy()\n",
    "df_claims = df_claims[df_claims['Sex'].notna()].copy()\n",
    "df_claims = df_claims[df_claims['DSFS'].notna()].copy()\n",
    "\n",
    "# transform categorical columns\n",
    "def transform1(row):\n",
    "    if pd.isna(row):\n",
    "        return 'None'\n",
    "    else:\n",
    "        return str(int(row))\n",
    "    \n",
    "df_claims['ProviderID'] = df_claims['ProviderID'].map(transform1)\n",
    "df_claims['Vendor'] = df_claims['Vendor'].map(transform1)\n",
    "df_claims['PCP'] = df_claims['PCP'].map(transform1)\n",
    "\n",
    "# handle missing values for categorical columns\n",
    "df_claims['ProcedureGroup'] = df_claims['ProcedureGroup'].fillna('None', inplace=False)\n",
    "df_claims['Specialty'] = df_claims['Specialty'].fillna('None', inplace=False)\n",
    "df_claims['PrimaryConditionGroup'] = df_claims['PrimaryConditionGroup'].fillna('None', inplace=False)\n",
    "df_claims['PlaceSvc'] = df_claims['PlaceSvc'].fillna('None', inplace=False)\n",
    "\n",
    "# encode number of columns\n",
    "df_claims['CharlsonIndex'] = df_claims['CharlsonIndex'].map({'0': 0, '1-2': 1.5, '3-4': 3.5, '5+': 7})\n",
    "df_claims['PayDelay'] = df_claims['PayDelay'].apply(lambda row: int(row) if row != '162+' else 200)\n",
    "df_claims['LengthOfStay'] = df_claims['LengthOfStay'].map({\n",
    "    '1 day': 1, '2 days': 2, '3 days': 3, '4 days': 4, '5 days': 5, '6 days': 6, '1- 2 weeks': 10, '2- 4 weeks': 21, '4- 8 weeks': 42,\n",
    "})\n",
    "df_claims['DSFS'] = df_claims['DSFS'].map({\n",
    "    '0- 1 month': 1, '1- 2 months': 2, '2- 3 months': 3, '3- 4 months': 4, '4- 5 months': 5, '5- 6 months': 6, \n",
    "    '6- 7 months': 7, '7- 8 months': 8, '8- 9 months': 9, '9-10 months': 10, '10-11 months': 11, '11-12 months': 12\n",
    "})\n",
    "\n",
    "# filter all large claims\n",
    "df_claims = df_claims[df_claims['DaysInHospital'] > 0].copy()\n",
    "print(df_claims.shape)\n",
    "\n",
    "# fill mean values for drug and lab counts\n",
    "df_claims['DrugCount'] = df_claims['DrugCount'].fillna(df_claims['DrugCount'].mean(), inplace=False)\n",
    "df_claims['LabCount'] = df_claims['LabCount'].fillna(df_claims['LabCount'].mean(), inplace=False)\n",
    "\n",
    "# drop length of stay\n",
    "df_claims = df_claims.drop(columns=['LengthOfStay'])\n",
    "\n",
    "#########################################################################################################################\n",
    "# Feature selection\n",
    "# numerical features\n",
    "def feature_agg(df, key):\n",
    "    ret = df.groupby(['MemberID', 'Year']).agg(\n",
    "        **{\n",
    "            key+'_mean': pd.NamedAgg(column=key, aggfunc='mean'),\n",
    "            key+'_std': pd.NamedAgg(column=key, aggfunc='std'),\n",
    "            key+'_max': pd.NamedAgg(column=key, aggfunc='max'),\n",
    "            key+'_min': pd.NamedAgg(column=key, aggfunc='min'),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ret[f'{key}_range'] = ret[f'{key}_max'] - ret[f'{key}_min']\n",
    "    ret = ret.reset_index()\n",
    "    ret = ret.drop(columns=[f'{key}_min'])\n",
    "    \n",
    "    df = pd.merge(df, ret, on=['MemberID', 'Year'], how='left')\n",
    "    df = df.drop(columns=[key])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_claims = feature_agg(df_claims, 'DSFS')\n",
    "df_claims = feature_agg(df_claims, 'PayDelay')\n",
    "df_claims = feature_agg(df_claims, 'CharlsonIndex')\n",
    "df_claims = feature_agg(df_claims, 'DrugCount')\n",
    "df_claims = feature_agg(df_claims, 'LabCount')\n",
    "\n",
    "def feature_agg2(df, key):\n",
    "    df = df.groupby(['MemberID', 'Year']).agg(key).nunique().reset_index(name = key+'_counts')\n",
    "    df = pd.merge(df_claims, df, on = ['MemberID', 'Year'], how = 'left')\n",
    "    return df\n",
    "\n",
    "df_claims = feature_agg2(df_claims, 'ProviderID')\n",
    "df_claims = feature_agg2(df_claims, 'Vendor')\n",
    "df_claims = feature_agg2(df_claims, 'PCP')\n",
    "df_claims = feature_agg2(df_claims, 'Specialty')\n",
    "df_claims = feature_agg2(df_claims, 'PlaceSvc')\n",
    "df_claims = feature_agg2(df_claims, 'PrimaryConditionGroup')\n",
    "df_claims = feature_agg2(df_claims, 'ProcedureGroup')\n",
    "ret = df_claims.groupby(['MemberID', 'Year']).size().reset_index(name = 'claim_counts')\n",
    "df_claims = pd.merge(df_claims, ret, on = ['MemberID', 'Year'], how = 'left')\n",
    "\n",
    "df_claims.fillna(0, inplace=True)\n",
    "\n",
    "# categoorical one-hot features\n",
    "top_k = 2\n",
    "for col in ['Specialty', 'PlaceSvc', 'PrimaryConditionGroup', 'ProcedureGroup']:\n",
    "    top_k_cols = pd.get_dummies(df_claims[col]).corrwith(df_claims['DaysInHospital']).abs().sort_values(ascending = False)[:top_k]\n",
    "    dummies = pd.get_dummies(df_claims[col])[top_k_cols.index]\n",
    "    dummies.columns = [f'{col}_{idx}' for idx in range(len(dummies.columns))]\n",
    "    df_claims = pd.concat([df_claims, dummies], axis = 1)\n",
    "    df_claims.drop(columns = [col], inplace = True)\n",
    "    \n",
    "df_claims = df_claims.drop(columns = ['MemberID', 'ProviderID', 'Vendor', 'PCP', 'Year'])\n",
    "\n",
    "#########################################################################################################################\n",
    "# Split data\n",
    "# columns\n",
    "num_cols = ['AgeAtFirstClaim']\n",
    "for col in ['CharlsonIndex', 'PayDelay', 'DrugCount', 'LabCount', 'DSFS']:\n",
    "    num_cols += [f'{col}_mean', f'{col}_std', f'{col}_max', f'{col}_range']\n",
    "for col in ['ProviderID', 'Vendor', 'PCP', 'Specialty', 'PlaceSvc', 'PrimaryConditionGroup', 'ProcedureGroup', 'claim']:\n",
    "    num_cols += [f'{col}_counts']\n",
    "print(len(num_cols))\n",
    "\n",
    "cat_cols = ['Sex', 'SupLOS', 'ClaimsTruncated']\n",
    "cat_cols += [f'{col}_{idx}' for col in ['Specialty', 'PlaceSvc', 'PrimaryConditionGroup', 'ProcedureGroup'] for idx in range(top_k)]\n",
    "print(len(cat_cols))\n",
    "\n",
    "target = 'DaysInHospital'\n",
    "\n",
    "# sample data\n",
    "df_claims_sample = df_claims.sample(n = 20000, random_state=42)\n",
    "\n",
    "# standardize\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_claims_sample[num_cols] = scaler.fit_transform(df_claims_sample[num_cols])\n",
    "scaler = MinMaxScaler()\n",
    "df_claims_sample[num_cols] = scaler.fit_transform(df_claims_sample[num_cols])\n",
    "\n",
    "# reorder target to be num cols, cat cols and target\n",
    "df_claims_sample = df_claims_sample[num_cols + cat_cols + [target]]\n",
    "\n",
    "print(df_claims_sample.shape)\n",
    "\n",
    "data = df_claims_sample\n",
    "\n",
    "avg_correlation_cols = avg_correlation(data)\n",
    "avg_correlation_cols = [col[0] for col in avg_correlation_cols if col[0] in num_cols]\n",
    "avg_correlation_cols = [col for col in avg_correlation_cols][:int(data.shape[1]*0.3)]\n",
    "\n",
    "# data config\n",
    "data_config = {\n",
    "    'target': target,\n",
    "    'features_idx': [idx for idx in range(0, data.shape[1]) if data.columns[idx] != target],\n",
    "    'split_col_idx': [data.columns.tolist().index(col) for col in avg_correlation_cols],\n",
    "    'ms_col_idx': [idx for idx in range(0, data.shape[1]) if data.columns[idx] in num_cols],\n",
    "    'obs_col_idx': [idx for idx in range(0, data.shape[1]) if data.columns[idx] in cat_cols],\n",
    "    \"num_cols\": len(num_cols),\n",
    "    'task_type': 'regression',\n",
    "    'clf_type': 'none',\n",
    "    'data_type': 'tabular'\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "486b3b6a",
   "metadata": {},
   "source": [
    "# import json\n",
    "# data.to_csv('./data/HHP_herritage_health/data_cleaned.csv', index=False)\n",
    "# with open('./data/HHP_herritage_health/data_config.json', 'w') as f:\n",
    "#     json.dump(data_config, f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ce70ef0",
   "metadata": {},
   "source": [
    "data.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fab1d47",
   "metadata": {},
   "source": [
    "data_config['split_col_idx']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90cf2ce2",
   "metadata": {},
   "source": [
    "avg_correlation(data[num_cols])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98a1da0f",
   "metadata": {},
   "source": [
    "data[num_cols].corrwith(data['DaysInHospital']).abs().sort_values(ascending = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b355ac6b",
   "metadata": {},
   "source": [
    "data_config"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33b3b1bb",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_claims_sample[num_cols]\n",
    "y = df_claims_sample[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c5ed5b3",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "\n",
    "model = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10]).fit(X_train, y_train)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)), np.sqrt(mean_squared_log_error(y_test, y_pred)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f0a873d",
   "metadata": {},
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=(128, 128), max_iter=1000, alpha=0.5, random_state=42, verbose=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
